{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K3ik-fVnEwMh"
   },
   "source": [
    "# Synchronize raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DNTj9JsvErX6"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zu26TTooOz8q"
   },
   "outputs": [],
   "source": [
    "import errno\n",
    "import glob\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "erJ5UGZUOw1K"
   },
   "outputs": [],
   "source": [
    "path = \"/home/roboy/Projects/RoboyMedium/data/unlabeled/20190825_OutsideAudimax/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1lhB6-g1Oz9G"
   },
   "outputs": [],
   "source": [
    "def get_raw_data(df_row):\n",
    "    \n",
    "    rostime = df_row.rostime\n",
    "    topic = df_row.topic\n",
    "    data = df_row.raw\n",
    "    \n",
    "    if topic == \"/camera/color/image_raw/compressed\":\n",
    "        nparr = np.fromstring(data[1], np.uint8)\n",
    "        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "        return rostime, img\n",
    "    \n",
    "    elif topic == '/camera/depth/image_rect_raw/compressed':\n",
    "        nparr = np.fromstring(data[1], np.uint8)\n",
    "        img = cv2.imdecode(nparr, 2)\n",
    "        return rostime, img\n",
    "            \n",
    "    elif topic == '/p2g_base_scans':\n",
    "        return rostime, data\n",
    "      \n",
    "    elif topic == '/ts_scans':\n",
    "        return rostime, data\n",
    "                \n",
    "    else:\n",
    "        return None;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YhyVGlhNOz9P"
   },
   "source": [
    "## Load data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KUYU21Csc0i9"
   },
   "outputs": [],
   "source": [
    "files = glob.glob(path + \"*.pkl\")\n",
    "files.sort()\n",
    "rosbag_files = [file for file in files if not file.split('/')[-1].startswith('walabot')]\n",
    "walabot_files = [file for file in files if file.split('/')[-1].startswith('walabot')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_idx = {\n",
    "    'p2g_0' : 0,\n",
    "    'p2g_1' : 0,\n",
    "    'p2g_2' : 0,\n",
    "    'p2g_3' : 0,\n",
    "    'ts3_0': 0,\n",
    "    'ts3_1': 0,\n",
    "    'frame' : 0\n",
    "}\n",
    "\n",
    "search_range = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/roboy/Projects/RoboyMedium/data/unlabeled/20190825_OutsideAudimax/dataset_2019-08-25-14-57-39_9.pkl',\n",
       " '/home/roboy/Projects/RoboyMedium/data/unlabeled/20190825_OutsideAudimax/merged_20190825_OutsideAudimax.pkl',\n",
       " '/home/roboy/Projects/RoboyMedium/data/unlabeled/20190825_OutsideAudimax/rostimes_synchronized.pkl',\n",
       " '/home/roboy/Projects/RoboyMedium/data/unlabeled/20190825_OutsideAudimax/synchronized_20190825_OutsideAudimax.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rosbag_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Videocreation and Synchronization\n",
    "In order to use openpose it is easiest to label one single video file and extract keypoints of each frame. To be able to do that, a video is created out of the camera data. To later synchronize the recorded radar data with the corresponding frame (and therefore the corresponding keypoints), a rostime list is created to link each data frame to the keypoints after labeling the visual data.\n",
    "\n",
    "At the end of the following cell a dataset is created containing:\n",
    "1. asd\n",
    "2. asd\n",
    "3. asd\n",
    "\n",
    "It is saved as 'synchronized_<date>_<PlaceOfRecording>'. It doesn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JZUzV2KuOz9T",
    "outputId": "b6005c0e-439a-4d9e-8133-69189506081c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing dataset_2019-08-25-14-57-39_9\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'topic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'topic'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f1d464453e61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         }\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'topic'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"/camera/color/image_raw/compressed\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# The frames are hardcoded in order to deal with missing data, i.e. that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'topic'"
     ]
    }
   ],
   "source": [
    "rostimes = []\n",
    "\n",
    "out = cv2.VideoWriter(path + 'raw_video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 25, (640, 480))\n",
    "\n",
    "dataset = pd.DataFrame()\n",
    "\n",
    "for i, name in enumerate(rosbag_files):\n",
    "  \n",
    "    begin_idx = dataset.shape[0] \n",
    "\n",
    "    filename = name.split('/')[-1].split('.')[0]\n",
    "\n",
    "    print(\"Start processing {}\".format(filename))\n",
    "  \n",
    "    try:\n",
    "        df = pd.read_pickle(name).sort_values(by='rostime')\n",
    "\n",
    "        search_idx = {\n",
    "            'p2g_0' : 0,\n",
    "            'p2g_1' : 0,\n",
    "            'p2g_2' : 0,\n",
    "            'p2g_3' : 0,\n",
    "            'ts3_0': 0,\n",
    "            'ts3_1': 0,\n",
    "            'frame' : 0\n",
    "        }\n",
    "        \n",
    "        frames = df[df['topic'] == \"/camera/color/image_raw/compressed\"]\n",
    "\n",
    "        # The frames are hardcoded in order to deal with missing data, i.e. that \n",
    "        # sensor locations are consistent over all measurements even if a sensor\n",
    "        # was missing in one dataset\n",
    "        p2g_scans = {}\n",
    "        p2g_scans['p2g_0'] = df[df.frame=='p2g_0']\n",
    "        p2g_scans['p2g_1'] = df[df.frame=='p2g_1']\n",
    "        p2g_scans['p2g_2'] = df[df.frame=='p2g_2']\n",
    "        p2g_scans['p2g_3'] = df[df.frame=='p2g_3']\n",
    "\n",
    "        ts3_scans = {}\n",
    "        ts3_scans['ts3_0'] = df[df.frame=='ts3_0']\n",
    "        ts3_scans['ts3_1'] = df[df.frame=='ts3_1']\n",
    "\n",
    "        for index, p2g_0_scan in p2g_scans['p2g_0'].iterrows():\n",
    "\n",
    "            rostime, _ = get_raw_data(p2g_0_scan)\n",
    "\n",
    "            # Build sample dict    \n",
    "            sample_dict = {'filename': filename,\n",
    "                         'rostime': rostime,\n",
    "                        }\n",
    "\n",
    "            # get frame with rostime closest to current radar scan\n",
    "            while frames.iloc[search_idx['frame']].rostime - rostime < 0:\n",
    "                search_idx['frame'] = search_idx['frame'] +1\n",
    "            \n",
    "            if (frames.iloc[search_idx['frame']].rostime - rostime) > 10e9:\n",
    "                print(\"No camera frame within one second found. Skipping!\")\n",
    "                print(frames.iloc[search_idx['frame']].rostime - rostime)\n",
    "                continue\n",
    "                \n",
    "            frame = frames.iloc[search_idx['frame'] ]\n",
    "            frame_raw = np.frombuffer(frame.raw[1], np.uint8)\n",
    "            frame_img = cv2.imdecode(frame_raw, cv2.IMREAD_COLOR)\n",
    "\n",
    "            out.write(frame_img)\n",
    "\n",
    "            rostimes.append(float(rostime))\n",
    "\n",
    "            # get ultrasonic targets closest to current radar scan\n",
    "            for id in range(0,2):\n",
    "                key = 'ts3_{}'.format(id)\n",
    "                try:        \n",
    "                    while ts3_scans[key].iloc[search_idx[key]].rostime - rostime < 0:\n",
    "                        search_idx[key] = search_idx[key] +1\n",
    "\n",
    "                    if (ts3_scans[key].iloc[search_idx[key]].rostime - rostime) > 10e9:\n",
    "                        print(\"No ts3 frame within one second found. Skipping!\")\n",
    "                        sample_dict[key] = ts3_scans[key].iloc[search_idx[key]].raw\n",
    "                    else:\n",
    "                        sample_dict[key] = []\n",
    "                except IndexError:\n",
    "                    sample_dict[key] = []\n",
    "\n",
    "            # get other p2g antennas closest to current radar scan\n",
    "            for id in range(0,4):\n",
    "                key = 'p2g_{}'.format(id)\n",
    "                try:\n",
    "                    while p2g_scans[key].iloc[search_idx[key]].rostime - rostime < 0:\n",
    "                        search_idx[key] = search_idx[key] +1\n",
    "                    if search_idx[key] >= p2g_scans[key].shape[0]:\n",
    "                        raise \"Time out exeption!\"\n",
    "                    \n",
    "                    if (p2g_scans[key].iloc[search_idx[key]].rostime - rostime) > 10e9:\n",
    "                        print(\"No {} frame within one second found. Skipping!\".format(key))\n",
    "                        raise \"Time out exeption!\"\n",
    "                        \n",
    "                    _, frame = get_raw_data(p2g_scans[key].iloc[search_idx[key]])\n",
    "                    sample_dict[key+\"_0real\"] = frame['antenna0real']\n",
    "                    sample_dict[key+\"_0imag\"] = frame['antenna0imag']\n",
    "                    sample_dict[key+\"_1real\"] = frame['antenna1real']\n",
    "                    sample_dict[key+\"_1imag\"] = frame['antenna1imag']  \n",
    "                except:\n",
    "                    sample_dict[key+\"_0real\"] = []\n",
    "                    sample_dict[key+\"_0imag\"] = []\n",
    "                    sample_dict[key+\"_1real\"] = []\n",
    "                    sample_dict[key+\"_1imag\"] = []               \n",
    "\n",
    "            # append to dataset\n",
    "            dataset = dataset.append(sample_dict, ignore_index=True)\n",
    "        \n",
    "        print('Finished processing {}'.format(filename))\n",
    "    \n",
    "    except IOError as exc:\n",
    "        if exc.errno != errno.EISDIR: # Do not fail if a directory is found, just ignore it.\n",
    "            print(exc) # Propagate other kinds of IOError.\n",
    "    except IndexError as exc:\n",
    "        print(exc)\n",
    "\n",
    "dataset.to_pickle(path + \"dataset_{}.pkl\".format(filename))\n",
    "print('\\n Overall duration: {}'.format((dataset.iloc[-1].rostime - dataset.iloc[0].rostime)/10e8))\n",
    "\n",
    "out.release() # Finish supervision video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store list of rostimes per video frame\n",
    "import pickle\n",
    "with open(path + 'rostimes_synchronized.pkl', 'wb') as f:\n",
    "    pickle.dump(rostimes, f)\n",
    "\n",
    "dataset.to_pickle(path + \"synchronized_{}.pkl\".format(path.split(\"/\")[-2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sync walabot dataframes into \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6xiJddBom0H-",
    "outputId": "c26067ea-0f01-4913-a248-d11d5727fd4d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "walabot_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NobDA4Aocdfw",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_sum = 0\n",
    "walabot_df = pd.DataFrame()\n",
    "for walabot_file in walabot_files:\n",
    "    print(walabot_file)\n",
    "    walabot_df = walabot_df.append(pd.read_pickle(walabot_file))\n",
    "    print(\"shape: \", walabot_df.shape)\n",
    "\n",
    "if 'timestamp' in walabot_df.columns:\n",
    "    dataset = dataset.sort_values(by=['rostime'])\n",
    "    walabot_df = walabot_df.sort_values(by=['timestamp'])\n",
    "\n",
    "    data_merged = pd.merge_asof(left=dataset, left_on='rostime',\n",
    "                          right=walabot_df, right_on='timestamp',\n",
    "                          tolerance=5*10e8\n",
    "                          )\n",
    "\n",
    "    data_merged.to_pickle(path + \"merged_{}.pkl\".format(path.split(\"/\")[-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "supervise_dataframes_infer_poses",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
