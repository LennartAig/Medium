{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VaPxBX7SuY3A"
   },
   "source": [
    "# Position2Go keypoint localization network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "AXprKWaHh1l-",
    "outputId": "e9db4f48-be65-48c2-d12a-110fe2a622bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version 2.2.4-tf\n",
      "tensorflow version 1.13.1\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.activations import *\n",
    "\n",
    "import sys, os, warnings, time, glob\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"keras version {}\".format(tf.keras.__version__)); del keras\n",
    "print(\"tensorflow version {}\".format(tf.__version__))\n",
    "\n",
    "from keypoints_localizer.tf_records_generator import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global variables\n",
    "EPOCHS = 30\n",
    "SUM_OF_ALL_DATASAMPLES = 200\n",
    "BATCHSIZE = 8\n",
    "SHUFFLE_BUFFER = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SET_PATH = \"/home/kingkolibri/10_catkin_ws/test_records/\"\n",
    "TRAIN_SET_PATH = \"/home/kingkolibri/10_catkin_ws/train_records/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/kingkolibri/10_catkin_ws/train_records/p2g_20190823-bauingenieurwesen.tfrecord']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files = glob.glob(TRAIN_SET_PATH + \"p2g_*.tfrecord\")\n",
    "test_files = glob.glob(TEST_SET_PATH + \"p2g_*.tfrecord\")\n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(filenames, repetitions=-1):\n",
    "    \n",
    "    # This works with arrays as well\n",
    "    dataset = tf.data.TFRecordDataset(filenames=filenames)\n",
    "    \n",
    "    # Maps the parser on every filepath in the array\n",
    "    dataset = dataset.map(parse_p2g_example, num_parallel_calls=8)\n",
    "    dataset = dataset.repeat(repetitions) # will go on forever        \n",
    "    dataset = dataset.shuffle(SHUFFLE_BUFFER)\n",
    "    dataset = dataset.batch(BATCHSIZE)\n",
    "    \n",
    "    # Create an iterator\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    # Create tf representation of the iterator\n",
    "    raw, _, heatmaps = iterator.get_next()\n",
    "    \n",
    "    return raw, heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv2d is incompatible with the layer: expected ndim=4, found ndim=5. Full shape received: [None, 2, 256, 64, 8]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-63592c0636d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'channels_last'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                padding=\"same\")(x)\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;31m# Build layer if applicable (if the `build` method has been overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m         \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1589\u001b[0m     \u001b[0;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m     input_spec.assert_input_compatibility(\n\u001b[0;32m-> 1591\u001b[0;31m         self.input_spec, inputs, self.name)\n\u001b[0m\u001b[1;32m   1592\u001b[0m     \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m                          \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                          str(x.shape.as_list()))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv2d is incompatible with the layer: expected ndim=4, found ndim=5. Full shape received: [None, 2, 256, 64, 8]"
     ]
    }
   ],
   "source": [
    "STEPS_PER_EPOCH= int(SUM_OF_ALL_DATASAMPLES / BATCHSIZE)\n",
    "\n",
    "#Get your datatensors\n",
    "inputs, labels = create_dataset(train_files)\n",
    "\n",
    "# Define Input\n",
    "model_input = tf.keras.layers.Input(tensor=inputs)\n",
    "\n",
    "# Encdoing layer\n",
    "x = model_input\n",
    "for i in range(0,5):\n",
    "    x = Conv2D(filters=8 + 8*i,\n",
    "               kernel_size=[5, 5],\n",
    "               data_format='channels_last',\n",
    "               padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x, training=True)\n",
    "    x =  Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters=8 + 8*i,\n",
    "           kernel_size=[5, 5],\n",
    "           strides=[2, 1],\n",
    "           data_format='channels_last',\n",
    "           padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x, training=True)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "# Decoding layer\n",
    "for i in range(0,3):\n",
    "    x = Conv2DTranspose(filters=32,\n",
    "                kernel_size=[6, 6],\n",
    "                strides=[2, 1],\n",
    "                padding=\"same\")(x)\n",
    "    x = Activation('relu')(x)\n",
    "       \n",
    "x = Conv2DTranspose(filters=13,\n",
    "            kernel_size=[4, 4],\n",
    "            strides=[2, 2],\n",
    "            padding=\"same\")(x)\n",
    "x = Activation('sigmoid')(x)\n",
    "\n",
    "# model_output = tf.keras.layers.Dense(32*32*13, activation='relu')(model_output)\n",
    "\n",
    "#Create your model\n",
    "localizer_model = tf.keras.models.Model(inputs=model_input, \n",
    "                                 outputs=x\n",
    "                                )\n",
    "\n",
    "\n",
    "# Describe model\n",
    "localizer_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile model\n",
    "localizer_model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.01),\n",
    "                        loss='mean_squared_error',\n",
    "                        metrics=['mean_squared_error', 'acc'],\n",
    "                        target_tensors=[labels]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "25/25 [==============================] - 7s 263ms/step - loss: 271.7155 - mean_squared_error: 271.7155 - acc: 0.1427\n",
      "Epoch 2/30\n",
      "25/25 [==============================] - 3s 136ms/step - loss: 304.0161 - mean_squared_error: 304.0161 - acc: 0.3295\n",
      "Epoch 3/30\n",
      "25/25 [==============================] - 4s 143ms/step - loss: 296.1530 - mean_squared_error: 296.1530 - acc: 0.5503\n",
      "Epoch 4/30\n",
      "25/25 [==============================] - 4s 143ms/step - loss: 290.9292 - mean_squared_error: 290.9292 - acc: 0.3239\n",
      "Epoch 5/30\n",
      "25/25 [==============================] - 4s 144ms/step - loss: 302.6887 - mean_squared_error: 302.6887 - acc: 0.2628\n",
      "Epoch 6/30\n",
      "25/25 [==============================] - 4s 146ms/step - loss: 269.0944 - mean_squared_error: 269.0944 - acc: 0.2715\n",
      "Epoch 7/30\n",
      "25/25 [==============================] - 4s 145ms/step - loss: 303.4221 - mean_squared_error: 303.4222 - acc: 0.3123\n",
      "Epoch 8/30\n",
      "25/25 [==============================] - 4s 144ms/step - loss: 295.9064 - mean_squared_error: 295.9064 - acc: 0.3237\n",
      "Epoch 9/30\n",
      "25/25 [==============================] - 4s 146ms/step - loss: 291.0063 - mean_squared_error: 291.0063 - acc: 0.3445\n",
      "Epoch 10/30\n",
      "25/25 [==============================] - 4s 145ms/step - loss: 303.3761 - mean_squared_error: 303.3762 - acc: 0.2994\n",
      "Epoch 11/30\n",
      "25/25 [==============================] - 4s 145ms/step - loss: 268.1251 - mean_squared_error: 268.1251 - acc: 0.2787\n",
      "Epoch 12/30\n",
      "25/25 [==============================] - 4s 145ms/step - loss: 303.1988 - mean_squared_error: 303.1988 - acc: 0.4829\n",
      "Epoch 13/30\n",
      "25/25 [==============================] - 4s 145ms/step - loss: 296.4064 - mean_squared_error: 296.4064 - acc: 0.4546\n",
      "Epoch 14/30\n",
      "25/25 [==============================] - 4s 145ms/step - loss: 291.2050 - mean_squared_error: 291.2050 - acc: 0.4196\n",
      "Epoch 15/30\n",
      "25/25 [==============================] - 4s 146ms/step - loss: 302.7536 - mean_squared_error: 302.7535 - acc: 0.4395\n",
      "Epoch 16/30\n",
      "25/25 [==============================] - 4s 145ms/step - loss: 268.1464 - mean_squared_error: 268.1465 - acc: 0.3922\n",
      "Epoch 17/30\n",
      "25/25 [==============================] - 4s 145ms/step - loss: 303.3262 - mean_squared_error: 303.3261 - acc: 0.6443\n",
      "Epoch 18/30\n",
      "25/25 [==============================] - 4s 145ms/step - loss: 296.2994 - mean_squared_error: 296.2994 - acc: 0.5619\n",
      "Epoch 19/30\n",
      "25/25 [==============================] - 4s 145ms/step - loss: 291.4265 - mean_squared_error: 291.4265 - acc: 0.5038\n",
      "Epoch 20/30\n",
      "25/25 [==============================] - 4s 146ms/step - loss: 302.6340 - mean_squared_error: 302.6340 - acc: 0.5642\n",
      "Epoch 21/30\n",
      "25/25 [==============================] - 4s 146ms/step - loss: 267.8982 - mean_squared_error: 267.8982 - acc: 0.4174\n",
      "Epoch 22/30\n",
      "25/25 [==============================] - 4s 146ms/step - loss: 303.3098 - mean_squared_error: 303.3098 - acc: 0.6740\n",
      "Epoch 23/30\n",
      "25/25 [==============================] - 4s 146ms/step - loss: 296.4373 - mean_squared_error: 296.4373 - acc: 0.5721\n",
      "Epoch 24/30\n",
      "25/25 [==============================] - 4s 141ms/step - loss: 291.6605 - mean_squared_error: 291.6605 - acc: 0.5407\n",
      "Epoch 25/30\n",
      "25/25 [==============================] - 4s 145ms/step - loss: 302.2867 - mean_squared_error: 302.2867 - acc: 0.5533\n",
      "Epoch 26/30\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 267.8721 - mean_squared_error: 267.8721 - acc: 0.5805\n",
      "Epoch 27/30\n",
      "25/25 [==============================] - 4s 141ms/step - loss: 303.3451 - mean_squared_error: 303.3451 - acc: 0.7365\n",
      "Epoch 28/30\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 296.6822 - mean_squared_error: 296.6822 - acc: 0.6236\n",
      "Epoch 29/30\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 291.5172 - mean_squared_error: 291.5172 - acc: 0.5694\n",
      "Epoch 30/30\n",
      "25/25 [==============================] - 4s 145ms/step - loss: 302.3295 - mean_squared_error: 302.3295 - acc: 0.5303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f173e65ca90>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "localizer_model.fit(epochs=EPOCHS,\n",
    "                    steps_per_epoch=STEPS_PER_EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(filenames, repetitions=-1):\n",
    "    \n",
    "    # This works with arrays as well\n",
    "    dataset = tf.data.TFRecordDataset(filenames=filenames)\n",
    "    \n",
    "    # Maps the parser on every filepath in the array\n",
    "    dataset = dataset.map(parse_p2g_example, num_parallel_calls=8)\n",
    "    dataset = dataset.repeat(repetitions) # will go on forever        \n",
    "    dataset = dataset.shuffle(SHUFFLE_BUFFER)\n",
    "    dataset = dataset.batch(BATCHSIZE)\n",
    "    \n",
    "    # Create an iterator\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    # Create tf representation of the iterator\n",
    "    _, rdm, heatmaps = iterator.get_next()\n",
    "    \n",
    "    return rdm, heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The model has multiple outputs, so `sample_weight` should be either a list or a dict. Provided `sample_weight` type not understood: Tensor(\"IteratorGetNext_13:2\", shape=(?, 128, 128, 13), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-6fbaa6a90a85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m localizer_model.evaluate(\n\u001b[1;32m      8\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_set_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     if (self.run_eagerly or (isinstance(x, iterator_ops.EagerIterator) and\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle)\u001b[0m\n\u001b[1;32m   2424\u001b[0m       \u001b[0;31m# `class_weight` arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2425\u001b[0m       sample_weights = training_utils.standardize_sample_weights(\n\u001b[0;32m-> 2426\u001b[0;31m           sample_weight, feed_output_names)\n\u001b[0m\u001b[1;32m   2427\u001b[0m       class_weights = training_utils.standardize_class_weights(\n\u001b[1;32m   2428\u001b[0m           class_weight, feed_output_names)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_sample_weights\u001b[0;34m(sample_weight, output_names)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstandardize_sample_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m   return standardize_sample_or_class_weights(sample_weight, output_names,\n\u001b[0;32m--> 417\u001b[0;31m                                              'sample_weight')\n\u001b[0m\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_sample_or_class_weights\u001b[0;34m(x_weight, output_names, weight_type)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;34m'The model has multiple outputs, so `'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mweight_type\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;34m'should be either a list or a dict. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         'Provided `' + weight_type + '` type not understood: ' + str(x_weight))\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The model has multiple outputs, so `sample_weight` should be either a list or a dict. Provided `sample_weight` type not understood: Tensor(\"IteratorGetNext_13:2\", shape=(?, 128, 128, 13), dtype=float32)"
     ]
    }
   ],
   "source": [
    "#Get your datatensors\n",
    "inputs, labels = create_dataset(test_files, repetitions=1)\n",
    "\n",
    "#Combine it with keras\n",
    "model_input = tf.keras.layers.Input(tensor=inputs)\n",
    "\n",
    "localizer_model.evaluate(\n",
    "    x=test_set_iterator,\n",
    "    verbose=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfRangeError",
     "evalue": "End of sequence\n\t [[node IteratorGetNext_7 (defined at <ipython-input-44-f3aeca157c14>:16) ]]\n\nCaused by op 'IteratorGetNext_7', defined at:\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-52-1d77d685d1e3>\", line 2, in <module>\n    inputs, labels = create_dataset(test_files)\n  File \"<ipython-input-44-f3aeca157c14>\", line 16, in create_dataset\n    _, rdm, heatmaps = iterator.get_next()\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 414, in get_next\n    output_shapes=self._structure._flat_shapes, name=name)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1685, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nOutOfRangeError (see above for traceback): End of sequence\n\t [[node IteratorGetNext_7 (defined at <ipython-input-44-f3aeca157c14>:16) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: End of sequence\n\t [[{{node IteratorGetNext_7}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-2cd0f1f9ad09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_all_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#execute init_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msample_rdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msample_heatmaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msample_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocalizer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: End of sequence\n\t [[node IteratorGetNext_7 (defined at <ipython-input-44-f3aeca157c14>:16) ]]\n\nCaused by op 'IteratorGetNext_7', defined at:\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-52-1d77d685d1e3>\", line 2, in <module>\n    inputs, labels = create_dataset(test_files)\n  File \"<ipython-input-44-f3aeca157c14>\", line 16, in create_dataset\n    _, rdm, heatmaps = iterator.get_next()\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 414, in get_next\n    output_shapes=self._structure._flat_shapes, name=name)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1685, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/kingkolibri/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nOutOfRangeError (see above for traceback): End of sequence\n\t [[node IteratorGetNext_7 (defined at <ipython-input-44-f3aeca157c14>:16) ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables()) #execute init_op\n",
    "    sample_rdm = sess.run(inputs)\n",
    "    sample_heatmaps = sess.run(labels)\n",
    "    sample_outputs = localizer_model.predict_on_batch(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize sample heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_columns = [\n",
    "    'LAnkle', \n",
    "    'LElbow', \n",
    "    'LHip', \n",
    "    'LKnee',\n",
    "    'LShoulder',\n",
    "    #['keypoint_0_LSmallToe_x', 'keypoint_0_LSmallToe_y'],\n",
    "    'LWrist',\n",
    "    #['keypoint_0_MidHip_x', 'keypoint_0_MidHip_y'],\n",
    "    #['keypoint_0_Neck_x', 'keypoint_0_Neck_y'],\n",
    "    'Nose',\n",
    "    'RAnkle',\n",
    "    #['keypoint_0_RBigToe_x','keypoint_0_RBigToe_y'], \n",
    "    #['keypoint_0_REar_x','keypoint_0_REar_y'], \n",
    "    'RElbow', \n",
    "    #['keypoint_0_REye_x','keypoint_0_REye_y'], \n",
    "    #['keypoint_0_RHeel_x','keypoint_0_RHeel_y'], \n",
    "    'RHip', \n",
    "    'RKnee', \n",
    "    'RShoulder',\n",
    "    #['keypoint_0_RSmallToe_x', 'keypoint_0_RSmallToe_y'], \n",
    "    'RWrist' \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize estimated keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = sample_outputs\n",
    "y_pred = sample_heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heigth = y_test.shape[1]\n",
    "width = y_test.shape[2]\n",
    "num_keypoints = y_test.shape[3]\n",
    "\n",
    "\n",
    "\n",
    "for i in np.random.randint(y_test.shape[0], size=(2,)):\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(3,3))\n",
    "  #  ax = fig.add_subplot(1,1,1)\n",
    "  #  ax.imshow(X_train[i,:,:,0], cmap=\"gray\")\n",
    "  #  ax.axis(\"off\")\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,3))\n",
    "    count = 1\n",
    "    \n",
    "    for j, keypoint in enumerate(keypoint_columns):\n",
    "        ax = fig.add_subplot(2, num_keypoints, count)\n",
    "        ax.set_title(keypoint)\n",
    "        ax.axis(\"off\")\n",
    "        count += 1\n",
    "        ax.imshow(y_pred[i,:,:,j])\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(\"prediction\")\n",
    "            \n",
    "    for j, keypoint in enumerate(keypoint_columns):\n",
    "        ax = fig.add_subplot(2, num_keypoints,count)\n",
    "        count += 1\n",
    "        ax.imshow(y_test[i,:,:,j])   \n",
    "        ax.axis(\"off\")\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(\"true\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize stick man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_pairs = [\n",
    "    [('Neck', 'RShoulder'), None],\n",
    "    [('Neck', 'LShoulder'), None],\n",
    "    [('RShoulder', 'RElbow'), None],\n",
    "    [('RElbow', 'RWrist'), None],\n",
    "    [('LShoulder', 'LElbow'), None],\n",
    "    [('LElbow', 'LWrist'), None],\n",
    "    [('Neck', 'RHip'), None],\n",
    "    [('RHip', 'RKnee'), None],\n",
    "    [('RKnee', 'RAnkle'), None],\n",
    "    [('Neck', 'LHip'), None],\n",
    "    [('LHip', 'LKnee'), None],\n",
    "    [('LKnee', 'LAnkle'), None],\n",
    "    [('Neck', 'Nose'), None],\n",
    "    [('Nose', 'REye'), None],\n",
    "    [('REye', 'REar'), None],\n",
    "    [('Nose', 'LEye'), None],\n",
    "    [('LEye', 'LEar'), None],\n",
    "    [('RShoulder', 'REar'), None],\n",
    "    [('LShoulder', 'LEar'), None],\n",
    "    [('LHip', 'LAnkle'), 'LKnee'],\n",
    "    [('RHip', 'RAnkle'), 'RKnee'],\n",
    "    [('RShoulder', 'RAnkle'), 'RElbow'],\n",
    "    [('LShoulder', 'LAnkle'), 'LElbow'],\n",
    "    [('RHip', 'LHip'), 'Neck'],\n",
    "    [('RHip', 'RShoulder'), 'Neck'],\n",
    "    [('LHip', 'LShoulder'), 'Neck'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_pred = {}\n",
    "body_true = {}\n",
    "for j, keypoint in enumerate(keypoint_columns):\n",
    "    x_pred = y_pred[i,:,:,j]\n",
    "    x_true = y_test[i,:,:,j]\n",
    "    body_pred[keypoint] = np.unravel_index(y_test[i,:,:,j].argmax(), y_test[i,:,:,j].shape)\n",
    "    body_true[keypoint] = np.unravel_index(y_pred[i,:,:,j].argmax(), y_pred[i,:,:,j].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first check the visualization of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((64,64,3), np.uint8)\n",
    "\n",
    "import cv2\n",
    "image_h, image_w = img.shape[:2]\n",
    "\n",
    "centers = {}\n",
    "\n",
    "# draw point\n",
    "for key in keypoint_columns:\n",
    "    if key not in body_true.keys():\n",
    "        continue\n",
    "\n",
    "    body_part = body_true[key]\n",
    "    center = (body_part[1], body_part[0])\n",
    "    centers[key] = center\n",
    "    img[center[1], center[0], :] =  [0, 255, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw line\n",
    "for pair_order, pair in enumerate(keypoint_pairs):\n",
    "    if pair[0][0] not in body_true.keys() or pair[0][1] not in body_true.keys() or pair[1] in body_true.keys():\n",
    "        continue\n",
    "\n",
    "    cv2.line(img, centers[pair[0][0]], centers[pair[0][1]], [255, 0, 0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take a look at the network output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((64,64,3), np.uint8)\n",
    "\n",
    "import cv2\n",
    "image_h, image_w = img.shape[:2]\n",
    "\n",
    "centers = {}\n",
    "\n",
    "# draw point\n",
    "for key in keypoint_columns:\n",
    "    if key not in body_pred.keys():\n",
    "        continue\n",
    "\n",
    "    body_part = body_pred[key]\n",
    "    center = (body_part[1], body_part[0])\n",
    "    centers[key] = center\n",
    "    img[center[1], center[0], :] =  [0, 255, 0]\n",
    "    \n",
    "# draw line\n",
    "for pair_order, pair in enumerate(keypoint_pairs):\n",
    "    if pair[0][0] not in body_pred.keys() or pair[0][1] not in body_pred.keys() or pair[1] in body_pred.keys():\n",
    "        continue\n",
    "\n",
    "    cv2.line(img, centers[pair[0][0]], centers[pair[0][1]], [255, 0, 0], 1)\n",
    "    \n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_keypoint_localization_network",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
